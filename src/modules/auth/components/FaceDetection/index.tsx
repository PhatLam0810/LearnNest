import React, { useRef, useEffect, useState } from 'react';
import Webcam from 'react-webcam';
import * as tf from '@tensorflow/tfjs';
import * as facemesh from '@tensorflow-models/facemesh';
import { usePathname, useRouter } from 'next/navigation';

const FaceDetection = () => {
  const webcamRef = useRef(null);
  const canvasRef = useRef(null);
  const [showWarning, setShowWarning] = useState(false);
  const [openCamera, setOpenCamera] = useState(true);
  const offFaceCountRef = useRef(0);
  const router = useRouter();
  const animationFrameIdRef = useRef(null);

  useEffect(() => {
    let model = null;
    let isMounted = true; // ðŸ‘ˆ Ä‘á»ƒ trÃ¡nh leak vÃ²ng láº·p

    const runFaceMesh = async () => {
      console.log('ðŸš€ Init TensorFlow backend...');
      await tf.setBackend('webgl');
      await tf.ready();
      console.log('âœ… TensorFlow backend ready');

      console.log('ðŸ“¦ Loading FaceMesh model...');
      model = await facemesh.load();
      console.log('âœ… FaceMesh model loaded');

      const detect = async () => {
        if (!isMounted) return; // ðŸ‘ˆ Ä‘Ã£ unmount thÃ¬ dá»«ng háº³n

        try {
          if (!webcamRef.current) {
            console.log('â¸ï¸ webcamRef chÆ°a sáºµn sÃ ng');
          } else if (webcamRef.current.video.readyState !== 4) {
            console.log('ðŸ“· Camera chÆ°a sáºµn sÃ ng');
          } else {
            const video = webcamRef.current.video;
            const videoWidth = video.videoWidth;
            const videoHeight = video.videoHeight;

            // gÃ¡n kÃ­ch thÆ°á»›c cho canvas vÃ  video
            webcamRef.current.video.width = videoWidth;
            webcamRef.current.video.height = videoHeight;
            canvasRef.current.width = videoWidth;
            canvasRef.current.height = videoHeight;

            console.log('ðŸŽ¥ Detecting frame...');
            const predictions = await model.estimateFaces({ input: video });
            const ctx = canvasRef.current.getContext('2d');
            ctx.clearRect(0, 0, videoWidth, videoHeight);

            if (predictions.length > 0) {
              console.log(`ðŸ˜€ PhÃ¡t hiá»‡n ${predictions.length} khuÃ´n máº·t`);

              predictions.forEach((prediction, idx) => {
                const keypoints = prediction.scaledMesh;

                // váº½ keypoints
                keypoints.forEach(([x, y]) => {
                  ctx.beginPath();
                  ctx.arc(x, y, 1.5, 0, 2 * Math.PI);
                  ctx.fillStyle = 'aqua';
                  ctx.fill();
                });

                // check hÆ°á»›ng máº·t
                const leftEye = keypoints[33];
                const rightEye = keypoints[263];
                const eyeDx = Math.abs(leftEye[0] - rightEye[0]);

                if (eyeDx < 50) {
                  offFaceCountRef.current += 1;
                  console.log(
                    'âš ï¸ Máº·t khÃ´ng nhÃ¬n tháº³ng:',
                    offFaceCountRef.current,
                  );
                } else {
                  offFaceCountRef.current = 0;
                  console.log('âœ… Máº·t nhÃ¬n tháº³ng');
                }

                if (offFaceCountRef.current >= 3) {
                  setShowWarning(true);
                } else {
                  setShowWarning(false);
                }
              });
            } else {
              offFaceCountRef.current += 1;
              console.log('âŒ KhÃ´ng tÃ¬m tháº¥y máº·t:', offFaceCountRef.current);

              if (offFaceCountRef.current >= 3) {
                setShowWarning(true);
              }
            }
          }
        } catch (err) {
          console.error('âŒ detect error:', err);
        }

        // tiáº¿p tá»¥c loop náº¿u cÃ²n mounted
        if (isMounted) {
          animationFrameIdRef.current = requestAnimationFrame(detect);
        }
      };

      console.log('â–¶ï¸ Báº¯t Ä‘áº§u detection loop...');
      detect();
    };

    if (openCamera) {
      runFaceMesh();
    }

    return () => {
      // cleanup
      isMounted = false;
      if (animationFrameIdRef.current) {
        cancelAnimationFrame(animationFrameIdRef.current);
        animationFrameIdRef.current = null;
        console.log('ðŸ›‘ Stop detection loop (cleanup)');
      }
    };
  }, [openCamera]);

  return (
    <div style={{ width: 640, height: 480 }}>
      <Webcam
        ref={webcamRef}
        audio={false}
        videoConstraints={{ facingMode: 'user' }}
        onUserMediaError={err => {
          alert(
            'âš ï¸ No webcam detected. Please connect a camera to use this feature.',
          );
          router.back(); // ðŸ‘ˆ Quay láº¡i trang trÆ°á»›c
          setOpenCamera(false);
        }}
        style={{
          position: 'absolute',
          left: 0,
          top: 0,
          width: 640,
          height: 480,
          backgroundColor: 'black',
          zIndex: 3,
        }}
      />

      <canvas
        ref={canvasRef}
        style={{
          position: 'absolute',
          left: 890,
          top: 0,
          width: 640,
          backgroundColor: 'red',
          height: 480,
          zIndex: 3,
        }}
      />

      {/* Modal cáº£nh bÃ¡o náº¿u khÃ´ng nhÃ¬n tháº³ng */}
      {showWarning && (
        <div
          style={{
            position: 'absolute',
            top: '30%',
            left: '50%',
            transform: 'translate(-50%, -50%)',
            backgroundColor: 'rgba(255, 0, 0, 0.85)',
            color: 'white',
            padding: 20,
            borderRadius: 10,
            zIndex: 1000,
            fontSize: 18,
            fontWeight: 'bold',
            textAlign: 'center',
          }}>
          ðŸš¨ Please look straight at the screen!
        </div>
      )}
    </div>
  );
};

export default FaceDetection;
